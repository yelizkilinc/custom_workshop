{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to deal with complex/large Documents"
      ],
      "metadata": {},
      "id": "60ec6048-44e4-4118-b16a-9c4c9cc78a3b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous notebook, we developed a solution for various types of files and data formats commonly found in organizations, and this covers big majority of the use cases. However, you will find that there are issues when dealing with questions that require answers from complex files. The complexity of these files arises from their length and the way information is distributed within them. Large documents are always a challenge for Search Engines.\n\nOne example of such complex files is Technical Specification Guides or Product Manuals, which can span hundreds of pages and contain information in the form of images, tables, forms, and more. Books are also complex due to their length and the presence of images or tables.\n\nThese files are typically in PDF format. To better handle these PDFs, we need a smarter parsing method that treats each document as a special source and processes them page by page (1 page = 1 chunk). The objective is to obtain more accurate and faster answers from our system. Fortunately, there are usually not many of these types of documents in an organization, allowing us to make exceptions and treat them differently.\n\nIf your use case is just PDFs, for example, you can just use [PyPDF library](https://pypi.org/project/pypdf/) or [Azure AI Document Intelligence SDK (former Form Recognizer)](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/overview?view=doc-intel-3.0.0), vectorize using OpenAI API and push the content to a vector-based index. And this is problably the simplest and fastest way to go.  However if your use case entails connecting to a datalake, or Sharepoint libraries or any other document data source with thousands of documents with multiple file types and that can change dynamically, then you would want to use the Ingestion and Document Cracking and AI-Enrichment capabilities of Azure Search engine, Notebooks 1-3, and avoid a lot of painful custom code. \n"
      ],
      "metadata": {},
      "id": "9281ac79-47cd-49d4-bdd4-7f5c173a947d"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "from azure.identity import ManagedIdentityCredential\n",
        "import openai\n",
        "\n",
        "\n",
        "from common.utils import parse_pdf, read_pdf_files, text_to_base64\n",
        "from common.prompts import DOCSEARCH_PROMPT\n",
        "from common.utils import CustomAzureSearchRetriever\n",
        "\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1727049202919
        }
      },
      "id": "15f6044e-463f-4988-bc46-a3c3d641c15c"
    },
    {
      "cell_type": "code",
      "source": [
        "BLOB_CONTAINER_NAME = \"books\"\n",
        "BASE_CONTAINER_URL = \"https://blobstoragejed5nzg3k2jp6.blob.core.windows.net/\" + BLOB_CONTAINER_NAME + \"/\" # YK\n",
        "# go to storage account->endpoints->blob service\n",
        "LOCAL_FOLDER = \"./data/books/\"\n",
        "#YK\n",
        "MODEL = \"gpt-4o\" # options: gpt-35-turbo, gpt-35-turbo-16k, gpt-4, gpt-4-32k \n",
        "\n",
        "os.makedirs(LOCAL_FOLDER,exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727049203977
        }
      },
      "id": "ac024b32-7926-40f7-91b2-46686fdf9e9e"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "#os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {},
      "id": "331692ba-b68e-4b99-9bae-5057da9a389d"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Specify the client ID of the User Managed Identity\n",
        "user_managed_identity_client_id = \"d30cba06-04c1-4065-a91d-8b7ce3b07b78\"  # Replace with your User Managed Identity client ID\n",
        "\n",
        "# Step 2: Fetch the access token using ManagedIdentityCredential and the client ID of the user-managed identity\n",
        "credential = ManagedIdentityCredential(client_id=user_managed_identity_client_id)\n",
        "token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "\n",
        "# Step 3: Set the access token in the OpenAI API\n",
        "openai.api_key = token.token\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = \"https://azuremlopenai.openai.azure.com/\"  # Replace with your OpenAI resource's base URL\n",
        "openai.api_version = \"2023-06-01-preview\"  # Use the correct API version\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727049206992
        }
      },
      "id": "4dafb0c7-f277-42fb-a017-01b4dc6c1e08"
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 75\n",
        "embedder = AzureOpenAIEmbeddings(openai_api_key=token.token,deployment=os.environ[\"EMBEDDING_DEPLOYMENT_NAME\"], chunk_size=batch_size, \n",
        "                                 max_retries=2, \n",
        "                                 retry_min_seconds= 60,\n",
        "                                 retry_max_seconds= 70)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1727049209999
        }
      },
      "id": "594ff0d4-56e3-4bed-843d-28c7a092069b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Manual Document Cracking with Push to Vector-based Index"
      ],
      "metadata": {},
      "id": "bb87c647-158c-4f85-b569-5b9462f06c83"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Within our demo storage account, we have a container named `books`, which holds 5 books of different lengths, languages, and complexities. Let's create a `cogsrch-index-books-vector` and load it with the pages of all these books.\n",
        "\n",
        "We begin by downloading these books to our local machine:"
      ],
      "metadata": {},
      "id": "75551868-1546-421b-a14e-e42618d88e61"
    },
    {
      "cell_type": "code",
      "source": [
        "books = [\"images.pdf\",\"azure-search.pdf\"]"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727048524154
        }
      },
      "id": "83192ead-036a-422f-b993-c6faea489153"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's download the files to the local `./data/` folder:"
      ],
      "metadata": {},
      "id": "dd867b2f-b5a1-443c-aa0a-ce914a66b3c9"
    },
    {
      "cell_type": "code",
      "source": [
        "for book in tqdm(books):\n",
        "    book_url = BASE_CONTAINER_URL + book + os.environ['BLOB_SAS_TOKEN']\n",
        "    urllib.request.urlretrieve(book_url, LOCAL_FOLDER+ book)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 2/2 [00:06<00:00,  3.04s/it]\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727044709058
        }
      },
      "id": "135434a4-e452-4036-b901-d5c41de27174"
    },
    {
      "cell_type": "code",
      "source": [
        "book_pages_map = dict()\n",
        "for book in books:\n",
        "    print(\"Extracting Text from\",book,\"...\")\n",
        "    \n",
        "    # Capture the start time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Parse the PDF\n",
        "    book_path = LOCAL_FOLDER+book\n",
        "    book_map = parse_pdf(file=book_path, form_recognizer=False, verbose=True)\n",
        "    book_pages_map[book]= book_map\n",
        "    \n",
        "    # Capture the end time and Calculate the elapsed time\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    print(f\"Parsing took: {elapsed_time:.6f} seconds\")\n",
        "    print(f\"{book} contained {len(book_map)} pages\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Extracting Text from images.pdf ...\nExtracting text using PyPDF\nParsing took: 0.049578 seconds\nimages.pdf contained 2 pages\n\nExtracting Text from azure-search.pdf ...\nExtracting text using PyPDF\nParsing took: 42.657654 seconds\nazure-search.pdf contained 2094 pages\n\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727047597985
        }
      },
      "id": "237607d9-f795-4314-9e0e-067e621023fb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Vector-based index\n",
        "\n",
        "\n",
        "Now that we have the content of the book's chunks (each page of each book) in the dictionary `book_pages_map`, let's create the Vector index in our Azure Search Engine where this content is going to land"
      ],
      "metadata": {},
      "id": "7f5f9b7d-99e6-426d-a47e-343c7e8b492e"
    },
    {
      "cell_type": "code",
      "source": [
        "book_index_name = \"srch-index-books-yk\""
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1727049215551
        }
      },
      "id": "7d46e7c5-49c4-40f3-bb2d-79a9afeab4b1"
    },
    {
      "cell_type": "code",
      "source": [
        "credential = ManagedIdentityCredential(client_id=\"d30cba06-04c1-4065-a91d-8b7ce3b07b78\")\n",
        "\n",
        "# Obtain an access token for the Azure Cognitive Search service\n",
        "token = credential.get_token(\"https://search.azure.com/.default\")\n",
        "\n",
        "print(f\"Access token: {token.token}\")\n",
        "\n",
        "# Construct the headers with the access token\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': f'Bearer {token.token}'\n",
        "    }\n",
        "\n",
        "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Access token: eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6Ikg5bmo1QU9Tc3dNcGhnMVNGeDdqYVYtbEI5dyIsImtpZCI6Ikg5bmo1QU9Tc3dNcGhnMVNGeDdqYVYtbEI5dyJ9.eyJhdWQiOiJodHRwczovL3NlYXJjaC5henVyZS5jb20iLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC8xNmIzYzAxMy1kMzAwLTQ2OGQtYWM2NC03ZWRhMDgyMGI2ZDMvIiwiaWF0IjoxNzI2OTg5MDc0LCJuYmYiOjE3MjY5ODkwNzQsImV4cCI6MTcyNzA3NTc3NCwiYWlvIjoiazJCZ1lOQTJqR3AwWDljNGYrV05VdUhsdVhkbEFRPT0iLCJhcHBpZCI6ImQzMGNiYTA2LTA0YzEtNDA2NS1hOTFkLThiN2NlM2IwN2I3OCIsImFwcGlkYWNyIjoiMiIsImlkcCI6Imh0dHBzOi8vc3RzLndpbmRvd3MubmV0LzE2YjNjMDEzLWQzMDAtNDY4ZC1hYzY0LTdlZGEwODIwYjZkMy8iLCJpZHR5cCI6ImFwcCIsIm9pZCI6ImNlN2VhNTVkLWFjZjktNDEwNy1hODkxLWNhMDRmNGQ0MTdiMyIsInJoIjoiMC5BVVlBRThDekZnRFRqVWFzWkg3YUNDQzIwNENqRFloZW1KaEJnYm5nV3h6Rk1WanhBQUEuIiwic3ViIjoiY2U3ZWE1NWQtYWNmOS00MTA3LWE4OTEtY2EwNGY0ZDQxN2IzIiwidGlkIjoiMTZiM2MwMTMtZDMwMC00NjhkLWFjNjQtN2VkYTA4MjBiNmQzIiwidXRpIjoiQkpOc0M3NU1DVVNfVVkyVG8tRVNBQSIsInZlciI6IjEuMCIsInhtc19pZHJlbCI6IjcgMTgiLCJ4bXNfbWlyaWQiOiIvc3Vic2NyaXB0aW9ucy9mZTM4YzM3Ni1iNDJhLTQ3NDEtOWU3Yy1mNWQ3YzMxZTU4NzMvcmVzb3VyY2Vncm91cHMveWVsaXpraWxpbmMtcmcvcHJvdmlkZXJzL01pY3Jvc29mdC5NYW5hZ2VkSWRlbnRpdHkvdXNlckFzc2lnbmVkSWRlbnRpdGllcy9NYW5hZ2VkSWRlbnRpdHlGb3JBTUwifQ.dQVkZLF9R0UzOyK1NbVehHVAKOgJD_SXR5JHYAqIQ1ac9-_43JjBSBIOfiUMJiXQacTfMWDYpmhTAtzX8qcT46aJBcDE8K1yFcbE0V6X66sflz4mlRkJjfTovsEP_AlAi4k_lGGIO5COiwlXciB_EqmeDj6ry-n7CIUo_clxt0Oz5DPvZmYDRnm2EvpW7saLqAOsCtsSiS0SYQ3R-LiWDRF8FVav2fI_E7FJ_pokSBvj7neUTmY62ZMVxR5dLbX_BAvEPV3iz86XIY3YJLi18BnsQciO45TYzAl_EzWSRVAc1JyzUmVo-Pa5dsdqcYtVmj7r2qvciXfjsu7nTnm2xw\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727049108479
        }
      },
      "id": "d4f5331f-1e83-44d7-848a-d11aaf9aa646"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Please note the following points regarding the index:\n",
        "\n",
        "- The ParentKey field is absent.\n",
        "- The page_num field is present.\n",
        "\n",
        "The absence of the ParentKey field is due to the utilization of a PUSH method, rather than a PULL method. This approach indicates that we are not leveraging the integrated indexing provided by the Azure AI Search engine. Instead, we are engaging in the process of parsing, performing OCR, and manually creating and pushing the content along with its vectors.\n",
        "\n",
        "This manual parsing process involves the use of either, the pyPDF library, or the Azure Document Intelligence API. These APIs allow for the segmentation of content by page rather than by a specified number of characters, which is the method employed by the Azure AI search indexer. Consequently, this enables the inclusion of page_num as a field in our index."
      ],
      "metadata": {},
      "id": "2faab899-977b-40d0-b36e-26f75ac07e54"
    },
    {
      "cell_type": "markdown",
      "source": [
        "REST API version 2023-10-01-Preview supports external and internal vectorization. This Notebook assumes an external vectorization strategy. This API also supports:\n    \n- vectorSearch algorithms, hnsw and exhaustiveKnn nearest neighbors, with parameters for indexing and scoring.\n- vectorProfiles for multiple combinations of algorithm configurations.\n\nVector search algorithms include **exhaustive k-nearest neighbors (KNN)** and **Hierarchical Navigable Small World (HNSW)**. Exhaustive KNN performs a brute-force search that scans the entire vector space. HNSW performs an approximate nearest neighbor (ANN) search. While KNN provides exact nearest neighbor search results with high accuracy, its computational cost and poor scalability make it impractical for large datasets or real-time applications. HNSW, on the other hand, offers a highly efficient and scalable solution for nearest neighbor searches by finding approximate nearest neighbors quickly, making it more suitable for large-scale and high-dimensional data applications.\n\n\ncheck [HERE](https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-create-index?tabs=config-2023-10-01-Preview%2Crest-2023-11-01%2Cpush%2Cportal-check-index) for the details of the vector configuration."
      ],
      "metadata": {},
      "id": "75d63e68-69a5-4b3b-8eb0-86da02cb7230"
    },
    {
      "cell_type": "code",
      "source": [
        "index_payload = {\n",
        "    \"name\": book_index_name,\n",
        "    \"vectorSearch\": {\n",
        "        \"algorithms\": [  # We are showing here 3 types of search algorithms configurations that you can do\n",
        "             {\n",
        "                 \"name\": \"my-hnsw-config-1\",\n",
        "                 \"kind\": \"hnsw\",\n",
        "                 \"hnswParameters\": {\n",
        "                     \"m\": 4,\n",
        "                     \"efConstruction\": 400,\n",
        "                     \"efSearch\": 500,\n",
        "                     \"metric\": \"cosine\"\n",
        "                 }\n",
        "             },\n",
        "             {\n",
        "                 \"name\": \"my-hnsw-config-2\",\n",
        "                 \"kind\": \"hnsw\",\n",
        "                 \"hnswParameters\": {\n",
        "                     \"m\": 8,\n",
        "                     \"efConstruction\": 800,\n",
        "                     \"efSearch\": 800,\n",
        "                     \"metric\": \"cosine\"\n",
        "                 }\n",
        "             },\n",
        "             {\n",
        "                 \"name\": \"my-eknn-config\",\n",
        "                 \"kind\": \"exhaustiveKnn\",\n",
        "                 \"exhaustiveKnnParameters\": {\n",
        "                     \"metric\": \"cosine\"\n",
        "                 }\n",
        "             }\n",
        "        ],\n",
        "        \"vectorizers\": [\n",
        "            {\n",
        "                \"name\": \"openai\",\n",
        "                \"kind\": \"azureOpenAI\",\n",
        "                \"azureOpenAIParameters\":\n",
        "                {\n",
        "                    \"resourceUri\" : os.environ['AZURE_OPENAI_ENDPOINT'],\n",
        "                    #\"apiKey\" : os.environ['AZURE_OPENAI_API_KEY'],\n",
        "                    \"deploymentId\" : os.environ['EMBEDDING_DEPLOYMENT_NAME'],\n",
        "                    \"modelName\" : os.environ['EMBEDDING_DEPLOYMENT_NAME'],\n",
        "                    \"authIdentity\": None\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        \"profiles\": [  # profiles is the diferent kind of combinations of algos and vectorizers\n",
        "            {\n",
        "             \"name\": \"my-vector-profile-1\",\n",
        "             \"algorithm\": \"my-hnsw-config-1\",\n",
        "             \"vectorizer\":\"openai\"\n",
        "            },\n",
        "            {\n",
        "             \"name\": \"my-vector-profile-2\",\n",
        "             \"algorithm\": \"my-hnsw-config-2\",\n",
        "             \"vectorizer\":\"openai\"\n",
        "            },\n",
        "            {\n",
        "             \"name\": \"my-vector-profile-3\",\n",
        "             \"algorithm\": \"my-eknn-config\",\n",
        "             \"vectorizer\":\"openai\"\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"semantic\": {\n",
        "        \"configurations\": [\n",
        "            {\n",
        "                \"name\": \"my-semantic-config\",\n",
        "                \"prioritizedFields\": {\n",
        "                    \"titleField\": {\n",
        "                        \"fieldName\": \"title\"\n",
        "                    },\n",
        "                    \"prioritizedContentFields\": [\n",
        "                        {\n",
        "                            \"fieldName\": \"chunk\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"prioritizedKeywordsFields\": []\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"fields\": [\n",
        "        {\"name\": \"id\", \"type\": \"Edm.String\", \"key\": \"true\", \"filterable\": \"true\" },\n",
        "        {\"name\": \"title\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
        "        {\"name\": \"chunk\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
        "        {\"name\": \"name\", \"type\": \"Edm.String\", \"searchable\": \"true\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
        "        {\"name\": \"location\", \"type\": \"Edm.String\", \"searchable\": \"false\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
        "        {\"name\": \"page_num\",\"type\": \"Edm.Int32\",\"searchable\": \"false\",\"retrievable\": \"true\"},\n",
        "        {\n",
        "            \"name\": \"chunkVector\",\n",
        "            \"type\": \"Collection(Edm.Single)\",\n",
        "            \"dimensions\": 1536,\n",
        "            \"vectorSearchProfile\": \"my-vector-profile-3\", # we picked profile 3 to show that this index uses eKNN vs HNSW (on prior notebooks)\n",
        "            \"searchable\": \"true\",\n",
        "            \"retrievable\": \"true\",\n",
        "            \"filterable\": \"false\",\n",
        "            \"sortable\": \"false\",\n",
        "            \"facetable\": \"false\"\n",
        "        }\n",
        "        \n",
        "    ],\n",
        "}\n",
        "\n",
        "r = requests.put(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name,\n",
        "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
        "print(r.status_code)\n",
        "print(r.ok)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "201\nTrue\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1727047193171
        }
      },
      "id": "2df4db6b-969b-4b91-963f-9334e17a4e3c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to debug errors\n",
        "# r.text"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {},
      "id": "36691ff0-c4c8-49d0-bfa8-3e076ece0ce5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload the Document chunks and its vectors to the Index"
      ],
      "metadata": {},
      "id": "3bc7dda9-4725-410e-9465-54f0298fc758"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code will iterate over each chunk of each book and use the Azure Search Rest API upload method to insert each document with its corresponding vector (using OpenAI embedding model) to the index."
      ],
      "metadata": {},
      "id": "d73e7600-7902-48d4-b199-9d9dc0a17aa0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process a batch of pages\n",
        "def process_batch(bookname, pages):\n",
        "    try:\n",
        "        contents = [page[2] for page in pages]\n",
        "        chunk_vectors = embedder.embed_documents(contents)\n",
        "        \n",
        "        upload_payload = {\"value\": []}\n",
        "        for i, page in enumerate(pages):\n",
        "            page_num = page[0] + 1\n",
        "            content = page[2]\n",
        "            book_url = BASE_CONTAINER_URL + bookname\n",
        "            \n",
        "            payload = {\n",
        "                \"@search.action\": \"upload\",\n",
        "                \"id\": text_to_base64(bookname + str(page_num)),\n",
        "                \"title\": f\"{bookname}_page_{str(page_num)}\",\n",
        "                \"chunk\": content,\n",
        "                \"chunkVector\": chunk_vectors[i],\n",
        "                \"name\": bookname,\n",
        "                \"location\": book_url,\n",
        "                \"page_num\": page_num\n",
        "            }\n",
        "            upload_payload[\"value\"].append(payload)\n",
        "        \n",
        "        r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name + \"/docs/index\",\n",
        "                          data=json.dumps(upload_payload), headers=headers, params=params)\n",
        "        if r.status_code != 200:\n",
        "            print(f\"Failed to upload batch of pages from {bookname}: {r.status_code}\")\n",
        "            print(r.text)\n",
        "    except Exception as e:\n",
        "        print(f\"Exception processing batch of pages from {bookname}: {e}\")\n",
        "        time.sleep(10)  # Wait before retrying\n",
        "        process_batch(bookname, pages)  # Retry the same batch"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1727047387069
        }
      },
      "id": "a94911cf-c95f-4306-8574-b56296f29b88"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for bookname, bookmap in book_pages_map.items():\n",
        "        print(\"Uploading chunks from\", bookname)\n",
        "        # Split bookmap into chunks of size chunk_size\n",
        "        for i in tqdm(range(0, len(bookmap), batch_size)):\n",
        "            batch = bookmap[i:i + batch_size]\n",
        "            process_batch(bookname, batch)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading chunks from images.pdf\nUploading chunks from azure-search.pdf\nCPU times: user 17.1 s, sys: 164 ms, total: 17.3 s\nWall time: 6min 13s\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n100%|██████████| 28/28 [06:10<00:00, 13.23s/it]\n"
        }
      ],
      "execution_count": 20,
      "metadata": {},
      "id": "793a3171-f8f0-4070-8a54-8a540828333c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}