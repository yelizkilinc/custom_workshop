{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Memory in LLMs"
      ],
      "metadata": {},
      "id": "01a8b5c0-87cb-4302-8e3c-dc809d0039fb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous Notebooks, we successfully explored how OpenAI models can enhance the results from Azure AI Search queries. \n",
        "\n",
        "However, we have yet to discover how to engage in a conversation with the LLM. With [Bing Chat](http://chat.bing.com/), for example, this is possible, as it can understand and reference the previous responses.\n",
        "\n",
        "There is a common misconception that LLMs (Large Language Models) have memory. This is not true. While they possess knowledge, they do not retain information from previous questions asked to them.\n",
        "\n",
        "In this Notebook, our goal is to illustrate how we can effectively \"endow the LLM with memory\" by employing prompts and context."
      ],
      "metadata": {},
      "id": "a2f73380-6395-4e9f-9c83-3f47a5d7e292"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory, CosmosDBChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables import ConfigurableFieldSpec\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "from typing import List\n",
        "import openai\n",
        "from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "#custom libraries that we will use later in the app\n",
        "from common.utils import CustomAzureSearchRetriever, get_answer\n",
        "from common.prompts import DOCSEARCH_PROMPT\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "import logging\n",
        "\n",
        "# Get the root logger\n",
        "logger = logging.getLogger()\n",
        "# Set the logging level to a higher level to ignore INFO messages\n",
        "logger.setLevel(logging.WARNING)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1727054603030
        }
      },
      "id": "733c782e-204c-47d0-8dae-c9df7091ab23"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's start with the basics\n",
        "Let's use a very simple example to see if the GPT model of Azure OpenAI have memory. We again will be using langchain to simplify our code "
      ],
      "metadata": {},
      "id": "3dc72b22-11c2-4df0-91b8-033d01829663"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"Tell me some use cases for reinforcement learning\"\n",
        "FOLLOW_UP_QUESTION = \"What was my prior question?\""
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1727054603191
        }
      },
      "id": "3eef5dc9-8b80-4085-980c-865fa41fa1f6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Specify the client ID of the User Managed Identity\n",
        "user_managed_identity_client_id = \"d30cba06-04c1-4065-a91d-8b7ce3b07b78\"  # Replace with your User Managed Identity client ID\n",
        "\n",
        "# Step 2: Fetch the access token using ManagedIdentityCredential and the client ID of the user-managed identity\n",
        "credential = ManagedIdentityCredential(client_id=user_managed_identity_client_id)\n",
        "token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "\n",
        "# Step 3: Set the access token in the OpenAI API\n",
        "openai.api_key = token.token\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = \"https://azuremlopenai.openai.azure.com/\"  # Replace with your OpenAI resource's base URL\n",
        "openai.api_version = \"2023-06-01-preview\"  # Use the correct API version"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727054603943
        }
      },
      "id": "f442960c-370a-4c52-8090-885c7bf88aae"
    },
    {
      "cell_type": "code",
      "source": [
        "COMPLETION_TOKENS = 1000\n",
        "# Create an OpenAI instance\n",
        "llm = AzureChatOpenAI(openai_api_key=token.token,azure_endpoint=openai.api_base,openai_api_version=openai.api_version,deployment_name=os.environ[\"GPT4o_DEPLOYMENT_NAME\"], \n",
        "                      temperature=0.5, max_tokens=COMPLETION_TOKENS,)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1727054604962
        }
      },
      "id": "a00181d5-bd76-4ce4-a256-75ac5b58c60f"
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a very simple prompt template, just the question as is:\n",
        "output_parser = StrOutputParser()\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an assistant that give thorough responses to users.\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1727054605960
        }
      },
      "id": "9502d0f1-fddf-40d1-95d2-a1461dcc498a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see what the GPT model responds\n",
        "chain = prompt | llm | output_parser\n",
        "response_to_initial_question = chain.invoke({\"input\": QUESTION})\n",
        "display(Markdown(response_to_initial_question))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions by performing actions in an environment to maximize some notion of cumulative reward. Here are several use cases across various domains:\n\n### 1. **Robotics**\n- **Autonomous Navigation**: RL is used to train robots to navigate complex environments, avoid obstacles, and find optimal paths.\n- **Manipulation Tasks**: Robots can learn to perform tasks such as picking and placing objects, assembly, and other intricate manipulations.\n\n### 2. **Gaming**\n- **Game Playing**: RL has been famously used in training agents to play games like Go, Chess, and video games (e.g., AlphaGo, AlphaZero, and agents playing Atari games).\n- **Game Design**: RL can assist in designing game levels or AI opponents that adapt to the player's skill level.\n\n### 3. **Finance**\n- **Algorithmic Trading**: RL is used to develop trading strategies that adapt to market conditions and optimize returns.\n- **Portfolio Management**: Agents can learn to allocate assets in a portfolio to maximize returns while managing risk.\n\n### 4. **Healthcare**\n- **Treatment Strategies**: RL can help in developing personalized treatment plans for patients by learning from historical data and patient responses.\n- **Drug Discovery**: RL can assist in optimizing the process of drug discovery, including the design and testing of new compounds.\n\n### 5. **Transportation**\n- **Autonomous Vehicles**: RL is used to train self-driving cars to navigate roads, make decisions, and interact safely with other vehicles and pedestrians.\n- **Traffic Management**: RL can optimize traffic light control to reduce congestion and improve traffic flow.\n\n### 6. **Industrial Automation**\n- **Process Optimization**: RL can optimize manufacturing processes, energy management, and resource allocation to improve efficiency and reduce costs.\n- **Predictive Maintenance**: RL can predict equipment failures and schedule maintenance activities to minimize downtime.\n\n### 7. **Natural Language Processing**\n- **Conversational Agents**: RL can be used to train chatbots and virtual assistants to handle conversations more effectively by learning from interactions.\n- **Machine Translation**: RL can improve the quality of machine translation by optimizing the translation process based on feedback.\n\n### 8. **Energy**\n- **Smart Grid Management**: RL can optimize the distribution of electricity in smart grids to balance supply and demand efficiently.\n- **Renewable Energy**: RL can help in optimizing the operation of renewable energy sources like wind and solar power to maximize output and efficiency.\n\n### 9. **Marketing**\n- **Personalized Recommendations**: RL can be used to develop recommendation systems that adapt to user preferences over time.\n- **Dynamic Pricing**: RL can optimize pricing strategies in real-time to maximize revenue and customer satisfaction.\n\n### 10. **Supply Chain Management**\n- **Inventory Management**: RL can optimize inventory levels to reduce costs and meet demand effectively.\n- **Logistics and Routing**: RL can improve the efficiency of logistics operations, including routing of delivery vehicles and warehouse management.\n\n### 11. **Education**\n- **Personalized Learning**: RL can create adaptive learning systems that tailor educational content to individual student needs and learning paces.\n- **Tutoring Systems**: RL can enhance intelligent tutoring systems to provide more effective and personalized feedback to students.\n\n### 12. **Space Exploration**\n- **Planetary Rovers**: RL can be used to train autonomous rovers to navigate and perform tasks on other planets.\n- **Satellite Management**: RL can optimize the operations of satellites, including orbit adjustments and resource management.\n\nReinforcement learning is a powerful tool that can be applied to a wide range of problems where decision-making and optimization are critical. The versatility and adaptability of RL make it suitable for many real-world applications."
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1727054613907
        }
      },
      "id": "c5c9903e-15c7-4e05-87a1-58e5a7917ba2"
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's ask a follow up question\n",
        "printmd(chain.invoke({\"input\": FOLLOW_UP_QUESTION}))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "I'm sorry, but I don't have access to previous interactions or any prior questions you may have asked. How can I assist you today?"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1727054614130
        }
      },
      "id": "99acaf3c-ce68-4b87-b24a-6065b15ff9a8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, it doesn't remember what it just responded, sometimes it responds based only on the system prompt, or just randomly. This proof that the LLM does NOT have memory and that we need to give the memory as a a conversation history as part of the prompt, like this:"
      ],
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "id": "a3e1c143-c95f-4566-a8b4-af8c42f08dd2"
    },
    {
      "cell_type": "code",
      "source": [
        "hist_prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"\n",
        "    {history}\n",
        "    Human: {question}\n",
        "    AI:\n",
        "\"\"\"\n",
        ")\n",
        "chain = hist_prompt | llm | output_parser"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1727054614312
        }
      },
      "id": "0946ce71-6285-432e-b011-9c2dc1ba7b8a"
    },
    {
      "cell_type": "code",
      "source": [
        "Conversation_history = \"\"\"\n",
        "Human: {question}\n",
        "AI: {response}\n",
        "\"\"\".format(question=QUESTION, response=response_to_initial_question)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1727054614474
        }
      },
      "id": "6d088e51-e5eb-4143-b87d-b2be429eb864"
    },
    {
      "cell_type": "code",
      "source": [
        "printmd(chain.invoke({\"history\":Conversation_history, \"question\": FOLLOW_UP_QUESTION}))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Your prior question was: \"Tell me some use cases for reinforcement learning.\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1727054614903
        }
      },
      "id": "d99e34ad-5539-44dd-b080-3ad05efd2f01"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bingo!**, so we now know how to create a chatbot using LLMs, we just need to keep the state/history of the conversation and pass it as context every time"
      ],
      "metadata": {},
      "id": "045e5af6-55d6-4353-b3f6-3275c95db00a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now that we understand the concept of memory via adding history as a context, let's go back to our GPT Smart Search engine"
      ],
      "metadata": {},
      "id": "eafd1694-0077-4aa8-bd01-e9f763ce36a3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "From Langchain website:\n",
        "    \n",
        "A memory system needs to support two basic actions: reading and writing. Recall that every chain defines some core execution logic that expects certain inputs. Some of these inputs come directly from the user, but some of these inputs can come from memory. A chain will interact with its memory system twice in a given run.\n",
        "\n",
        "    AFTER receiving the initial user inputs but BEFORE executing the core logic, a chain will READ from its memory system and augment the user inputs.\n",
        "    AFTER executing the core logic but BEFORE returning the answer, a chain will WRITE the inputs and outputs of the current run to memory, so that they can be referred to in future runs.\n",
        "    \n",
        "So this process adds delays to the response, but it is a necessary delay :)"
      ],
      "metadata": {},
      "id": "9787ffb6-2b11-4b03-92fc-9443cd1f2ab9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](./images/memory_diagram.png)"
      ],
      "metadata": {},
      "id": "f36e8f14-e566-4ae9-a7d4-6dee7f469dad"
    },
    {
      "cell_type": "code",
      "source": [
        "index1_name = \"srch-index-files-yk\"\n",
        "index2_name = \"srch-index-csv-yk\"\n",
        "#index3_name = \"srch-index-books-yk\"\n",
        "indexes = [index1_name, index2_name]#, index3_name]"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1727054619360
        }
      },
      "id": "ef9f459b-e8b8-40b9-a94d-80c079968594"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize our custom retriever \n",
        "retriever = CustomAzureSearchRetriever(indexes=indexes, topK=10, reranker_threshold=1)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1727054620200
        }
      },
      "id": "b01852c2-6192-496c-adff-4270f9380469"
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you check closely in prompts.py, there is an optional variable in the `DOCSEARCH_PROMPT` called `history`. Now it is the time to use it. It is basically a place holder were we will inject the conversation in the prompt so the LLM is aware of it before it answers."
      ],
      "metadata": {},
      "id": "633937e8-18e6-43f2-b4d5-fc36157a4d97"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now let's add memory to it:**"
      ],
      "metadata": {},
      "id": "035fa6e6-226c-400f-a504-30255385f43b"
    },
    {
      "cell_type": "code",
      "source": [
        "store = {} # Our first memory will be a dictionary in memory\n",
        "\n",
        "# We have to define a custom function that takes a session_id and looks somewhere\n",
        "# (in this case in a dictionary in memory) for the conversation\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1727054622976
        }
      },
      "id": "3c8c9381-08d0-4808-9ab1-78156ca1be6e"
    },
    {
      "cell_type": "code",
      "source": [
        "# We use our original chain with the retriever but removing the StrOutputParser\n",
        "chain = (\n",
        "    {\n",
        "        \"context\": itemgetter(\"question\") | retriever, \n",
        "        \"question\": itemgetter(\"question\"),\n",
        "        \"history\": itemgetter(\"history\")\n",
        "    }\n",
        "    | DOCSEARCH_PROMPT\n",
        "    | llm\n",
        ")\n",
        "\n",
        "## Then we pass the above chain to another chain that adds memory to it\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain_with_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"question\",\n",
        "    history_messages_key=\"history\",\n",
        ") | output_parser"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1727054623958
        }
      },
      "id": "48ff51e1-2b1e-4c67-965d-1c2e2f55e005"
    },
    {
      "cell_type": "code",
      "source": [
        "# This is where we configure the session id\n",
        "config={\"configurable\": {\"session_id\": \"abc123\"}}"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1727054624965
        }
      },
      "id": "0e582915-243f-42cb-bb1e-c35a20ee0b9f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice below, that we are adding a `history` variable in the call. This variable will hold the chat historywithin the prompt."
      ],
      "metadata": {},
      "id": "9ff493b1-b133-4880-a040-e80f7460e7af"
    },
    {
      "cell_type": "code",
      "source": [
        "printmd(chain_with_history.invoke({\"question\": QUESTION}, config=config))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "printing response\n<Response [200]>\nprinting response\n<Response [200]>\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Reinforcement learning (RL) has a wide array of applications across various fields, leveraging its ability to learn optimal actions through trial and error. Here are some notable use cases:\n\n1. **Robotics**: RL is extensively used in robotics for tasks such as robotic manipulation, autonomous navigation, and robotic control. It enables robots to learn complex tasks in dynamic environments by receiving feedback from their actions and adjusting accordingly.\n\n2. **Game Playing**: One of the most famous applications of RL is in playing games. Algorithms like AlphaGo have demonstrated RL's capability by defeating human champions in complex games like Go. RL is also used in other games like chess, StarCraft, and various video games to develop intelligent agents that can learn and master the game.\n\n3. **Autonomous Vehicles**: RL is crucial in developing self-driving cars. It helps in decision-making processes such as lane changing, speed control, and collision avoidance by learning from the environment and optimizing driving strategies.\n\n4. **Healthcare**: In healthcare, RL can be used for personalized treatment planning, optimizing drug dosages, and managing chronic diseases. It can learn from patient data to provide tailored treatment recommendations that improve patient outcomes.\n\n5. **Finance**: RL is applied in algorithmic trading, portfolio management, and financial forecasting. It helps in making trading decisions by learning from historical data and market trends to maximize returns and minimize risks.\n\n6. **Natural Language Processing (NLP)**: RL is used in NLP for tasks like dialogue management in conversational agents, machine translation, and text summarization. It helps in optimizing responses and improving the interaction quality by learning from user feedback.\n\n7. **Industrial Automation**: In industrial settings, RL is used for optimizing manufacturing processes, predictive maintenance, and energy management. It helps in improving efficiency, reducing downtime, and cutting operational costs by learning optimal strategies from the operational data.\n\n8. **Marketing**: RL can optimize marketing strategies by learning from consumer behavior data. It helps in personalized advertising, dynamic pricing, and recommendation systems to enhance customer engagement and increase sales.\n\nThese use cases illustrate the versatility and potential of reinforcement learning in solving complex problems and optimizing performance across various domains."
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1727054635964
        }
      },
      "id": "d91a7ff4-6148-459d-917c-37302805dd09"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remembers\n",
        "printmd(chain_with_history.invoke({\"question\": FOLLOW_UP_QUESTION},config=config))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "printing response\n<Response [200]>\nprinting response\n<Response [200]>\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Your prior question was: \"Tell me some use cases for reinforcement learning.\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1727054648917
        }
      },
      "id": "25dfc233-450f-4671-8f1c-0b446e46f048"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remembers\n",
        "printmd(chain_with_history.invoke({\"question\": \"Thank you! Good bye\"},config=config))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "printing response\n<Response [200]>\nprinting response\n<Response [200]>\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "You're welcome! If you have any more questions in the future, feel free to ask. Goodbye!"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1727054659351
        }
      },
      "id": "c67073c2-9a82-4e44-a9e2-48fe868c1634"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using CosmosDB as persistent memory\n",
        "\n",
        "In previous cell we have added local RAM memory to our chatbot. However, it is not persistent, it gets deleted once the app user's session is terminated. It is necessary then to use a Database for persistent storage of each of the bot user conversations, not only for Analytics and Auditing, but also if we wish to provide recommendations in the future. \n",
        "\n",
        "Here we will store the conversation history into CosmosDB for future auditing purpose.\n",
        "We will use a class in LangChain use CosmosDBChatMessageHistory"
      ],
      "metadata": {},
      "id": "87405173"
    },
    {
      "cell_type": "code",
      "source": [
        "credential = ManagedIdentityCredential(client_id=\"d30cba06-04c1-4065-a91d-8b7ce3b07b78\")"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1727054663071
        }
      },
      "id": "82dd25f6-f396-4f3e-a338-b43ab35147eb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the function to retrieve the conversation\n",
        "\n",
        "def get_session_history(session_id: str, user_id: str) -> CosmosDBChatMessageHistory:\n",
        "    cosmos = CosmosDBChatMessageHistory(\n",
        "        credential=credential,\n",
        "        cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
        "        cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
        "        cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
        "        connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
        "        session_id=session_id,\n",
        "        user_id=user_id\n",
        "        )\n",
        "\n",
        "    # prepare the cosmosdb instance\n",
        "    cosmos.prepare_cosmos()\n",
        "    return cosmos\n"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1727054663944
        }
      },
      "id": "d87cc7c6-5ef1-4492-b133-9f63a392e223"
    },
    {
      "cell_type": "code",
      "source": [
        "chain_with_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"question\",\n",
        "    history_messages_key=\"history\",\n",
        "    history_factory_config=[\n",
        "        ConfigurableFieldSpec(\n",
        "            id=\"user_id\",\n",
        "            annotation=str,\n",
        "            name=\"User ID\",\n",
        "            description=\"Unique identifier for the user.\",\n",
        "            default=\"\",\n",
        "            is_shared=True,\n",
        "        ),\n",
        "        ConfigurableFieldSpec(\n",
        "            id=\"session_id\",\n",
        "            annotation=str,\n",
        "            name=\"Session ID\",\n",
        "            description=\"Unique identifier for the conversation.\",\n",
        "            default=\"\",\n",
        "            is_shared=True,\n",
        "        ),\n",
        "    ],\n",
        ") | output_parser"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1727054664944
        }
      },
      "id": "94f4179b-c1c7-49da-9c80-a42c275ed4d6"
    },
    {
      "cell_type": "code",
      "source": [
        "# This is where we configure the session id and user id\n",
        "random_session_id = \"session\"+ str(random.randint(1, 1000))\n",
        "ramdom_user_id = \"user\"+ str(random.randint(1, 1000))\n",
        "\n",
        "config={\"configurable\": {\"session_id\": random_session_id, \"user_id\": ramdom_user_id}}"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1727054668083
        }
      },
      "id": "8cf1f1f0-6e46-4136-9f33-4e46617b7d4f"
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "{'configurable': {'session_id': 'session247', 'user_id': 'user913'}}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1727054669065
        }
      },
      "id": "0b20c00c-4098-4970-84e5-f71ea7615c65"
    },
    {
      "cell_type": "code",
      "source": [
        "printmd(chain_with_history.invoke({\"question\": QUESTION}, config=config))\n",
        "#Cosmosdb role assignment by power shell is needed\n",
        "# $resourceGroupName=\"ai-bootcamp\"\n",
        "# $accountName=\"cosmosdb-account-jed5nzg3k2jp6\"\n",
        "# $readOnlyRoleDefinitionId=\"00000000-0000-0000-0000-000000000002\"\n",
        "# $principalId=\"ce7ea55d-acf9-4107-a891-ca04f4d417b3\"\n",
        "# az cosmosdb sql role assignment create --account-name $accountName --resource-group $resourceGroupName --scope \"/\" --principal-id $principalId --role-definition-id $readOnlyRoleDefinitionId\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "printing response\n<Response [200]>\nprinting response\n<Response [200]>\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize cumulative rewards. Here are some notable use cases for reinforcement learning:\n\n1. **Robotics:**\n   - RL is extensively used in robotics for tasks such as navigation, manipulation, and control. Robots can learn to perform complex tasks by interacting with their environment and receiving feedback. For example, RL can enable a robotic arm to learn how to grasp objects of different shapes and sizes.\n\n2. **Autonomous Vehicles:**\n   - RL algorithms are employed to train self-driving cars to make decisions in real-time, such as lane keeping, obstacle avoidance, and path planning. The car learns to navigate through different driving scenarios by receiving rewards for safe and efficient driving behaviors.\n\n3. **Healthcare:**\n   - In healthcare, RL can be used for personalized treatment plans. For example, it can optimize the dosing of medications for patients with chronic diseases by learning from patient responses to different dosages over time.\n\n4. **Finance:**\n   - RL is used in finance for portfolio management, algorithmic trading, and risk management. It helps in making investment decisions by learning to balance the trade-off between risk and return based on historical market data.\n\n5. **Gaming:**\n   - RL has achieved significant success in gaming, where it is used to train AI agents to play games at superhuman levels. Notable examples include AlphaGo, which defeated human champions in the game of Go, and OpenAI's Dota 2 bot, which competes with professional players.\n\n6. **Industrial Automation:**\n   - RL is applied in industrial automation for optimizing manufacturing processes, such as controlling the temperature and pressure in chemical plants, or scheduling and routing in logistics and supply chain management.\n\n7. **Natural Language Processing (NLP):**\n   - In NLP, RL is used for tasks like dialogue systems and chatbots. It helps in training models to generate more human-like and contextually appropriate responses by learning from interactions with users.\n\n8. **Energy Management:**\n   - RL can optimize energy consumption in smart grids and buildings by learning to adjust heating, cooling, and lighting systems based on occupancy patterns and weather forecasts.\n\nThese use cases highlight the versatility of reinforcement learning across various domains, where it helps in making intelligent decisions by learning from interactions with the environment."
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1727054679917
        }
      },
      "id": "7e3c32f4-f883-4045-91f9-ca317c2d01fe"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remembers\n",
        "printmd(chain_with_history.invoke({\"question\": FOLLOW_UP_QUESTION},config=config))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "printing response\n<Response [200]>\nprinting response\n<Response [200]>\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Your prior question was: \"Tell me some use cases for reinforcement learning.\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1727054694109
        }
      },
      "id": "7e29643b-a531-4117-8e85-9c88a625cf02"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remembers\n",
        "printmd(chain_with_history.invoke(\n",
        "    {\"question\": \"Can you tell me a one line summary of our conversation?\"},\n",
        "    config=config))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "printing response\n<Response [200]>\nprinting response\n<Response [200]>\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "You asked for use cases of reinforcement learning, and I provided examples across various domains including robotics, autonomous vehicles, healthcare, finance, gaming, industrial automation, natural language processing, and energy management."
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1727054700903
        }
      },
      "id": "50146f05-5ef6-484f-a8ec-9631643054f2"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    printmd(chain_with_history.invoke(\n",
        "    {\"question\": \"Thank you very much!\"},\n",
        "    config=config))\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "printing response\n<Response [200]>\nprinting response\n<Response [200]>\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "You're welcome! If you have any more questions or need further assistance, feel free to ask. Have a great day!"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1727054705908
        }
      },
      "id": "8bc02369-904c-4063-93e1-fff24fe6a3ab"
    },
    {
      "cell_type": "code",
      "source": [
        "printmd(chain_with_history.invoke(\n",
        "    {\"question\": \"I do have one more question, why did you give me a one line summary?\"},\n",
        "    config=config))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "printing response\n<Response [200]>\nprinting response\n<Response [200]>\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "You asked for a one-line summary of our conversation, so I provided it to concisely encapsulate the main points we discussed. If you have any other questions or need more detailed information, feel free to ask!"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1727054714919
        }
      },
      "id": "87d60faa-1446-4c07-8970-0f9712c33b2f"
    },
    {
      "cell_type": "code",
      "source": [
        "printmd(chain_with_history.invoke(\n",
        "    {\"question\": \"why not 2?\"},\n",
        "    config=config))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "printing response\n<Response [200]>\nprinting response\n<Response [200]>\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "I provided a one-line summary because that's what you specifically requested. If you would like a more detailed summary or additional information, I'm happy to provide that as well. Just let me know what you need!"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1727054720083
        }
      },
      "id": "cfe748aa-6116-4a7a-97e6-f1c680dd23ad"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's check our Azure CosmosDB to see the whole conversation\n"
      ],
      "metadata": {},
      "id": "cdc5ac98"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![CosmosDB Memory](./images/cosmos-chathistory.png)"
      ],
      "metadata": {},
      "id": "f5e30694-ae2a-47bb-a5c7-db51ecdbba1e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n##### Adding memory to our application allows the user to have a conversation, however this feature is not something that comes with the LLM, but instead, memory is something that we must provide to the LLM in form of context of the question.\n\nWe added persitent memory using CosmosDB.\n\nWe also can notice that the current chain that we are using is smart, but not that much. Although we have given memory to it, it searches for similar docs everytime, regardless of the input. This doesn't seem efficient, but regardless, we are very close to finish our first RAG-talk to your data Bot.\n\n\n## <u>Important Note</u>:<br>\nAs we proceed, while all the code will remain compatible with GPT-3.5 models (1106 or newer), we highly recommend transitioning to GPT-4. Here's why:\n\n**GPT-3.5-Turbo** can be likened to a 7-year-old child. You can provide it with concise instructions, but it struggles sometimes to follow them accurately (not too reliable). Additionally, its limited \"memory\" (token context) can make sustained conversations challenging. Its response are also simple not deep.\n\n**GPT-4** exhibits the capabilities of a 10-12-year-old child. It possesses enhanced reasoning skills, consistently adheres to instructions and its answers are beter. It has extended memory retention (larger context size) for instructions, and it excels at following them. Its responses are deep and thorough.\n"
      ],
      "metadata": {},
      "id": "6789cada-23a3-451a-a91a-0906ceb0bd14"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEXT\n",
        "We know now how to do a Smart Search Engine that can power a chatbot!! great!\n",
        "\n",
        "In the next notebook 6, we are going to build our first RAG bot. In order to do this we will introduce the concept of Agents."
      ],
      "metadata": {},
      "id": "c629ebf4-aced-45b7-a6a2-315810d37d48"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "f53a8f7a-5e28-4d5f-9a33-0a3be0536b0f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}